<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>AR Try-On Pro 2026</title>
    <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <style>
        body { margin: 0; overflow: hidden; background: #000; font-family: 'Segoe UI', sans-serif; }
        #video-canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; z-index: -1; transform: scaleX(-1); }
        #status-ui { position: absolute; top: 20px; left: 50%; transform: translateX(-50%); z-index: 100; text-align: center; width: 80%; }
        .badge { background: rgba(0,255,204,0.15); backdrop-filter: blur(10px); color: #00ffcc; padding: 12px 24px; border-radius: 50px; border: 1px solid #00ffcc; font-weight: bold; font-size: 14px; box-shadow: 0 0 20px rgba(0,255,204,0.2); display: inline-block; }
        #debug-log { color: #888; font-size: 10px; margin-top: 10px; font-family: monospace; }
    </style>
</head>
<body>

    <div id="status-ui">
        <div class="badge" id="main-status">INITIALIZING AI ENGINE...</div>
        <div id="debug-log">Waiting for camera...</div>
    </div>

    <video id="input_video" style="display:none" playsinline muted autoplay></video>
    <canvas id="video-canvas"></canvas>

    <a-scene embedded vr-mode-ui="enabled: false" renderer="alpha: true; antialias: true; colorManagement: true;">
        <a-assets>
            <a-asset-item id="jacket-file" src="Jeans Denim Jacket.glb"></a-asset-item>
        </a-assets>

        <a-entity id="jacket-anchor" visible="false">
            <a-entity id="jacket-model" 
                      gltf-model="#jacket-file" 
                      position="0 -0.5 0" 
                      rotation="0 180 0" 
                      scale="4 4 4">
            </a-entity>
        </a-entity>

        <a-light type="ambient" intensity="1.5"></a-light>
        <a-camera position="0 1.6 0" look-controls-enabled="false" wasd-controls-enabled="false"></a-camera>
    </a-scene>

    <script>
        const videoElement = document.getElementById('input_video');
        const canvasElement = document.getElementById('video-canvas');
        const canvasCtx = canvasElement.getContext('2d');
        const jacketAnchor = document.getElementById('jacket-anchor');
        const statusBadge = document.getElementById('main-status');
        const debugLog = document.getElementById('debug-log');

        function updateLog(msg) { debugLog.innerText = `[LOG]: ${msg}`; }

        // 1. Initialize Pose Engine
        const pose = new Pose({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`
        });

        pose.setOptions({
            modelComplexity: 1,
            smoothLandmarks: true,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        // 2. Tracking Logic
        pose.onResults((results) => {
            if (statusBadge.innerText.includes("INITIALIZING")) {
                statusBadge.innerText = "MIRROR ACTIVE: STAND BACK";
            }

            // Draw Background Video
            canvasElement.width = videoElement.videoWidth;
            canvasElement.height = videoElement.videoHeight;
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.restore();

            if (!results.poseLandmarks) {
                jacketAnchor.setAttribute('visible', 'false');
                updateLog("No body detected");
                return;
            }

            jacketAnchor.setAttribute('visible', 'true');
            updateLog("Body Tracked! Landmarks: 33");

            // Landmarks 11/12 are shoulders
            const lS = results.poseLandmarks[11];
            const rS = results.poseLandmarks[12];
            
            // Positioning
            const midX = (lS.x + rS.x) / 2;
            const midY = (lS.y + rS.y) / 2;
            const posX = (0.5 - midX) * 4.5; 
            const posY = (0.5 - midY) * 3 + 1.6;
            jacketAnchor.setAttribute('position', `${posX} ${posY} -2.5`);

            // Dynamic Scaling
            const dist = Math.sqrt(Math.pow(lS.x - rS.x, 2) + Math.pow(lS.y - rS.y, 2));
            const baseScale = dist * 4.5; 
            jacketAnchor.setAttribute('scale', `${baseScale} ${baseScale} ${baseScale}`);

            // Rotation
            const angle = Math.atan2(rS.y - lS.y, rS.x - lS.x);
            jacketAnchor.setAttribute('rotation', `0 0 ${angle * (180 / Math.PI)}`);
        });

        // 3. Start Camera & Fail-Safe
        const camera = new Camera(videoElement, {
            onFrame: async () => {
                try {
                    await pose.send({image: videoElement});
                } catch (e) {
                    updateLog("Pose Error: " + e.message);
                }
            },
            width: 1280,
            height: 720
        });

        camera.start().then(() => {
            updateLog("Camera Started Successfully");
        }).catch(err => {
            updateLog("Camera Failed: " + err.message);
            statusBadge.innerText = "CAMERA ERROR";
        });

        // Fail-safe: If model doesn't load
        document.querySelector('#jacket-model').addEventListener('model-error', () => {
            updateLog("ERROR: .glb file not found or corrupted!");
            statusBadge.innerText = "MODEL ERROR";
        });
    </script>
</body>
</html>
