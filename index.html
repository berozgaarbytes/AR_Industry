<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>VaaS: Smart Fitting Validator</title>
    <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <style>
        body { margin: 0; overflow: hidden; background: #000; font-family: 'Segoe UI', sans-serif; }
        
        #ui-layer { 
            position: fixed; bottom: 30px; left: 50%; transform: translateX(-50%); 
            z-index: 999; display: flex; gap: 15px; background: rgba(0,0,0,0.9); 
            padding: 15px 25px; border-radius: 50px; border: 2px solid #00ffcc;
            box-shadow: 0 0 20px rgba(0, 255, 204, 0.3);
        }

        button { 
            background: transparent; border: 1px solid #00ffcc; color: #00ffcc; 
            padding: 10px 18px; border-radius: 20px; font-weight: bold; cursor: pointer;
            transition: 0.2s;
        }

        button:active { background: #00ffcc; color: #000; }

        #snap-btn { background: #00ffcc; color: #000; border: none; }

        #video-canvas { 
            position: absolute; top: 0; left: 0; width: 100vw; height: 100vh; 
            object-fit: cover; z-index: 1; transform: scaleX(-1); 
        }

        a-scene { position: absolute; top: 0; left: 0; width: 100vw; height: 100vh; z-index: 2; }
    </style>
</head>
<body>

    <div id="ui-layer">
        <button onclick="userY -= 0.05">‚¨áÔ∏è LOWER</button>
        <button id="snap-btn" onclick="localSave()">üì∏ SAVE SNAPSHOT</button>
        <button onclick="userY += 0.05">‚¨ÜÔ∏è RAISE</button>
        <button onclick="userScale -= 0.1">‚ûñ NARROW</button>
        <button onclick="userScale += 0.1">‚ûï WIDER</button>
    </div>

    <video id="input_video" style="display:none" playsinline muted autoplay></video>
    <canvas id="video-canvas"></canvas>

    <a-scene embedded vr-mode-ui="enabled: false" renderer="alpha: true; antialias: true; preserveDrawingBuffer: true;">
        <a-assets>
            <a-asset-item id="jacket-file" src="Jeans Denim Jacket.glb"></a-asset-item>
        </a-assets>

        <a-entity id="jacket-anchor" visible="false">
            <a-entity id="jacket-wrapper" rotation="0 180 180">
                <a-entity id="jacket-model" gltf-model="#jacket-file"></a-entity>
            </a-entity>
        </a-entity>

        <a-light type="ambient" intensity="2"></a-light>
        <a-light type="directional" position="0 2 1" intensity="1.5"></a-light>
        <a-camera position="0 1.6 0" look-controls-enabled="false" wasd-controls-enabled="false"></a-camera>
    </a-scene>

    <script>
        const videoElement = document.getElementById('input_video');
        const canvasElement = document.getElementById('video-canvas');
        const canvasCtx = canvasElement.getContext('2d');
        const jacketAnchor = document.getElementById('jacket-anchor');
        const jacketModel = document.getElementById('jacket-model');
        
        // Settings
        let userY = -0.35; 
        let userScale = 1.0; 
        let modelWidth = 1;

        // 1. AUTO-ALIGNMENT (Centering the 3D model)
        jacketModel.addEventListener('model-loaded', () => {
            const obj = jacketModel.getObject3D('mesh');
            const box = new THREE.Box3().setFromObject(obj);
            const size = new THREE.Vector3();
            box.getSize(size);
            modelWidth = size.x;
            // Snap the top of the jacket to the anchor point
            jacketModel.setAttribute('position', `0 ${-(size.y/2)} 0`);
        });

        // 2. POSE TRACKING (MediaPipe)
        const pose = new Pose({ locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}` });
        pose.setOptions({ modelComplexity: 1, smoothLandmarks: true, minDetectionConfidence: 0.6 });

        pose.onResults((results) => {
            canvasElement.width = videoElement.videoWidth;
            canvasElement.height = videoElement.videoHeight;
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

            if (results.poseLandmarks && modelWidth > 0) {
                jacketAnchor.setAttribute('visible', 'true');
                const lS = results.poseLandmarks[11]; // Left Shoulder
                const rS = results.poseLandmarks[12]; // Right Shoulder

                // --- PERFECT FIT MATH ---
                // Shoulder distance in 2D space
                const sDist = Math.sqrt(Math.pow(lS.x - rS.x, 2) + Math.pow(lS.y - rS.y, 2));
                
                // Calculated Z-Depth (Perspective Scaling)
                const posZ = -1.2 / (sDist * 1.5) - 1.0; 

                // Mapping X, Y with Z-correction
                const posX = (0.5 - (lS.x + rS.x) / 2) * (Math.abs(posZ) * 1.8);
                const posY = (0.5 - (lS.y + rS.y) / 2) * (Math.abs(posZ) * 1.2) + 1.6 + userY;
                jacketAnchor.setAttribute('position', `${posX} ${posY} ${posZ}`);

                // Scale adjustment based on proximity
                const finalScale = (sDist * Math.abs(posZ) * 2.8 * userScale) / modelWidth;
                jacketAnchor.setAttribute('scale', `${finalScale} ${finalScale} ${finalScale}`);

                // Rotation (Tilt & Turn)
                const tilt = Math.atan2(rS.y - lS.y, rS.x - lS.x) * (180 / Math.PI);
                const turn = (lS.z - rS.z) * 100; // Y-axis rotation
                jacketAnchor.setAttribute('rotation', `0 ${180 + turn} ${tilt}`);
            } else {
                jacketAnchor.setAttribute('visible', 'false');
            }
            canvasCtx.restore();
        });

        // 3. CAPTURE & SAVE (Direct to Device)
        function localSave() {
            // Create a temporary canvas to merge video + 3D
            const finalCanvas = document.createElement('canvas');
            finalCanvas.width = canvasElement.width;
            finalCanvas.height = canvasElement.height;
            const ctx = finalCanvas.getContext('2d');

            // 1. Draw the background (Video) - Flip back for natural view
            ctx.save();
            ctx.scale(-1, 1);
            ctx.drawImage(canvasElement, -finalCanvas.width, 0);
            ctx.restore();

            // 2. Draw the foreground (3D A-Frame Layer)
            const scene = document.querySelector('a-scene');
            ctx.drawImage(scene.renderer.domElement, 0, 0, finalCanvas.width, finalCanvas.height);

            // 3. Trigger Download
            const link = document.createElement('a');
            link.download = `VaaS_Validation_${Date.now()}.png`;
            link.href = finalCanvas.toDataURL("image/png");
            link.click();
        }

        const camera = new Camera(videoElement, {
            onFrame: async () => { await pose.send({image: videoElement}); },
            width: 1280, height: 720
        });
        camera.start();
    </script>
</body>
</html>
